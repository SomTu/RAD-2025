{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SomTu/RAD-2025/blob/main/code/01RAD_Ex12_python.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sXrQyd0oWEmt"
      },
      "source": [
        "# Kaggle house data set\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9BKKVRZXwXIJ"
      },
      "source": [
        "\n",
        "## Downloading the Kaggle house rent dataset\n",
        "\n",
        "The dataset we will use comes from Kaggle:\n",
        "\n",
        "- *House Rent Prediction Dataset*  \n",
        "  https://www.kaggle.com/datasets/iamsouravbanerjee/house-rent-prediction-dataset/data\n",
        "\n",
        "To download directly from Kaggle inside this notebook you need a Kaggle\n",
        "API token (see *Account ? API ? Create New Token* on Kaggle). The cell\n",
        "below assumes you have configured your `KAGGLE_USERNAME` and\n",
        "`KAGGLE_KEY` environment variables or placed `kaggle.json` in the\n",
        "standard location.\n",
        "\n",
        "Exampe of Auto NB - let's beat it\n",
        "\n",
        "https://www.kaggle.com/code/sahityasetu/boosting-algorithms-for-machine-learning\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FOYqDPp5wXIL"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Download the Kaggle house rent dataset using kagglehub (no API key needed for public data)\n",
        "try:\n",
        "    import kagglehub  # lightweight helper for Kaggle datasets\n",
        "except ImportError:  # pragma: no cover\n",
        "    %pip install -q kagglehub\n",
        "    import kagglehub\n",
        "\n",
        "# Download latest version of the dataset; this returns a local directory path\n",
        "path = kagglehub.dataset_download(\"iamsouravbanerjee/house-rent-prediction-dataset\")\n",
        "print(\"Path to dataset files:\", path)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NSuSSbXUwXIM"
      },
      "outputs": [],
      "source": [
        "\n",
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "\n",
        "# `path` is a directory returned by kagglehub; locate the CSV inside it\n",
        "dataset_dir = Path(path)\n",
        "candidates = list(dataset_dir.rglob(\"House_Rent_Dataset.csv\"))\n",
        "if not candidates:\n",
        "    raise FileNotFoundError(f\"House_Rent_Dataset.csv not found under {dataset_dir}\")\n",
        "\n",
        "csv_path = candidates[0]\n",
        "print(\"Loading data from:\", csv_path)\n",
        "house = pd.read_csv(csv_path)\n",
        "print(\"Shape:\", house.shape)\n",
        "house_orig = house\n",
        "house.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import re\n",
        "import pandas as pd\n",
        "import statsmodels.formula.api as smf\n",
        "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
        "import statsmodels.api as sm\n",
        "import pandas as pd\n",
        "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
        "\n"
      ],
      "metadata": {
        "id": "XphAT5gd7UD_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Zk5i55Rx-bLI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(list(house.columns))\n",
        "print(house.describe(include='all'), \"\\n\\n\")\n",
        "print(house.isna().sum())\n",
        "sns.pairplot(data=house)\n",
        "\n",
        "for col in house.columns:\n",
        "    print(f\"\\nColumn: {col}\")\n",
        "    print(house[col].unique())\n"
      ],
      "metadata": {
        "id": "CiK40QDR5roY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The columns are ['Posted On', 'BHK', 'Rent', 'Size', 'Floor', 'Area Type', 'Area Locality', 'City', 'Furnishing Status', 'Tenant Preferred', 'Bathroom', 'Point of Contact']\n",
        "\n",
        "'Posted On' should not have any effect on Rent, therefore will not be used for the model.\n",
        "\n",
        "'Area Type' has half as many unique values as there are total of samples. Author sees no sensible way to include them in the model.\n",
        "\n",
        "Initial feature choice is ['BHK', 'Size', 'Floor', 'City', 'Furnishing Status', 'Bathroom']"
      ],
      "metadata": {
        "id": "9xz19_Rz8w5L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "def add_floor_columns(\n",
        "    df: pd.DataFrame,\n",
        "    source_col: str,\n",
        "    current_col: str = \"current_floor\",\n",
        "    max_col: str = \"max_floor\",\n",
        "    inplace: bool = True,\n",
        "):\n",
        "    \"\"\"\n",
        "    Parses floor information from a column and adds two new columns:\n",
        "    current floor and max floor.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    df : pd.DataFrame\n",
        "        Input dataframe\n",
        "    source_col : str\n",
        "        Column containing floor strings (e.g. '3 out of 10')\n",
        "    current_col : str, optional\n",
        "        Name of output column for current floor\n",
        "    max_col : str, optional\n",
        "        Name of output column for max floor\n",
        "    inplace : bool, optional\n",
        "        If True, modifies df in place. If False, returns a copy.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    pd.DataFrame\n",
        "        DataFrame with added columns\n",
        "    \"\"\"\n",
        "\n",
        "    if not inplace:\n",
        "        df = df.copy()\n",
        "\n",
        "    floor_map = {\n",
        "        \"Ground\": 0,\n",
        "        \"Upper Basement\": -1,\n",
        "        \"Lower Basement\": -2,\n",
        "    }\n",
        "\n",
        "    pattern = re.compile(r\"(.+?)\\s+out of\\s+(\\d+)$\")\n",
        "\n",
        "    def parse_value(val):\n",
        "        if not isinstance(val, str):\n",
        "            return (np.nan, np.nan)\n",
        "\n",
        "        val = val.strip()\n",
        "        match = pattern.match(val)\n",
        "\n",
        "        if not match:\n",
        "            return (np.nan, np.nan)\n",
        "\n",
        "        raw_floor, max_floor = match.groups()\n",
        "        max_floor = int(max_floor)\n",
        "\n",
        "        raw_floor = raw_floor.strip()\n",
        "\n",
        "        # Numeric floor\n",
        "        if raw_floor.isdigit():\n",
        "            return (int(raw_floor), max_floor)\n",
        "\n",
        "        # Named floor\n",
        "        if raw_floor in floor_map:\n",
        "            return (floor_map[raw_floor], max_floor)\n",
        "\n",
        "        return (np.nan, np.nan)\n",
        "\n",
        "    df[[current_col, max_col]] = (\n",
        "        df[source_col]\n",
        "        .apply(parse_value)\n",
        "        .apply(pd.Series)\n",
        "    )\n",
        "\n",
        "    return df\n",
        "\n",
        "house = add_floor_columns(house, source_col='Floor')\n",
        "\n",
        "# rewriting the four NaN floors. 'max_floor' is estimated using the mean ~0.5\n",
        "house.loc[2553, 'current_floor'] = 3\n",
        "house.loc[2883, 'current_floor'] = 1\n",
        "house.loc[4490, 'current_floor'] = 1\n",
        "house.loc[4560, 'current_floor'] = 1\n",
        "\n",
        "house.loc[2553, 'max_floor'] = 6\n",
        "house.loc[2883, 'max_floor'] = 2\n",
        "house.loc[4490, 'max_floor'] = 2\n",
        "house.loc[4560, 'max_floor'] = 2\n",
        "\n",
        "house['floor_ratio'] = house['current_floor'] / house['max_floor']\n",
        "#price_skew = house[\"Rent\"].skew()\n",
        "#print(f\"Rent skewness: {price_skew:.2f} (right-skew suggests log-transforming the target)\")\n",
        "for column in house.select_dtypes(include='number').columns:\n",
        "    print(f\"Skewness in {column} is {house[column].skew():.2f}.\")\n",
        "print(\"DataFrame head:\\n\",house.head())\n",
        "print(house[house['floor_ratio'].isna()])\n",
        "print()\n",
        "print(f\"floor_ratio mean: {house['floor_ratio'].mean():.3f}\")\n"
      ],
      "metadata": {
        "id": "ITYiQ_oH8uNO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# transforming Rent\n",
        "house['log_Rent'] = np.log(house['Rent'])\n",
        "\n",
        "\n",
        "house['Furnishing_Status'] = house['Furnishing Status']\n",
        "house['Area_Type'] = house['Area Type']\n",
        "\n",
        "# Rent distribution\n",
        "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
        "sns.histplot(house[\"Rent\"], bins=40, kde=True, color=\"steelblue\", ax=axes[0])\n",
        "axes[0].set_title(\"Rent distribution (linear scale)\")\n",
        "axes[0].set_xlabel(\"Rent\")\n",
        "axes[0].set_ylabel(\"Count\")\n",
        "\n",
        "sns.histplot(np.log1p(house[\"Rent\"]), bins=40, kde=True, color=\"darkorange\", ax=axes[1])\n",
        "axes[1].set_title(\"Rent distribution (log1p scale)\")\n",
        "axes[1].set_xlabel(\"log(1 + Rent)\")\n",
        "axes[1].set_ylabel(\"Count\")\n",
        "\n",
        "for column in house.select_dtypes(include='number').columns:\n",
        "    print(f\"Skewness in {column} is {house[column].skew():.2f}.\")"
      ],
      "metadata": {
        "id": "HcO_0y_Wghx3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this case, log-transforming did not help with some skewness"
      ],
      "metadata": {
        "id": "fOcvT_05gWbz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sns.pairplot(data=house)\n"
      ],
      "metadata": {
        "id": "EGSIMWGgBXXS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "After log transforming the data, there are some noticable linear trends.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "KMMDlObuBXNf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "house.head()"
      ],
      "metadata": {
        "id": "5H9Qm_g-wkKq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "Initial model with a very bad result:\n",
        "\n"
      ],
      "metadata": {
        "id": "Xy1raNVeTBEe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = smf.ols(\"Rent ~ BHK + Size + current_floor + max_floor + C(Furnishing_Status) + Bathroom\", data=house).fit()\n",
        "print(model.summary())"
      ],
      "metadata": {
        "id": "o2p9dbxSBmPi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Since BHK is the number of bedrooms, halls and kitchens, it is very likely that there is going to be some multicollinearity between it and Size. We will therefore keep only the size. At the same time, the 'max_floor' and 'current_floor' are somewhat related as well as 'current_floor' never exceeds 'max_floor'. For this reason, we will omit the 'max_floor'.\n",
        "\n",
        "At the same time, we will use log-scaled variants of the feature"
      ],
      "metadata": {
        "id": "RoARkiAYTcHe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Main effects\n",
        "NUMERIC_FEATURES = [\n",
        "    \"Size\",\n",
        "    \"floor_ratio\",\n",
        "    \"Bathroom\"\n",
        "]\n",
        "\n",
        "CATEGORICAL_FEATURES = [\n",
        "    \"City\",\n",
        "    \"Furnishing_Status\",\n",
        "    \"Area_Type\"\n",
        "]\n",
        "\n",
        "# Interactions\n",
        "INTERACTIONS = [\n",
        "    \"Size:C(City)\",\n",
        "    \"C(Furnishing_Status):C(City)\",\n",
        "    \"Size:Bathroom\"\n",
        "]\n",
        "\n",
        "# Main effects part\n",
        "main_effects = (\n",
        "    NUMERIC_FEATURES\n",
        "    + [f\"C({c})\" for c in CATEGORICAL_FEATURES]\n",
        ")\n",
        "\n",
        "# Full formula\n",
        "formula = \"log_Rent ~ \" + \" + \".join(main_effects + INTERACTIONS)\n",
        "\n",
        "model = smf.ols(formula, data=house).fit()\n",
        "print(model.summary())"
      ],
      "metadata": {
        "id": "FMr8Q7jkT9LR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dummy encode categorical variables\n",
        "X = pd.get_dummies(\n",
        "    house[NUMERIC_FEATURES],\n",
        "    drop_first=True\n",
        ")\n",
        "\n",
        "# Add interaction terms manually\n",
        "# Size × City\n",
        "for col in X.filter(like=\"City_\").columns:\n",
        "    X[f\"Size:{col}\"] = house[\"Size\"] * X[col]\n",
        "\n",
        "# Furnishing × City\n",
        "for f in X.filter(like=\"Furnishing_Status_\").columns:\n",
        "    for c in X.filter(like=\"City_\").columns:\n",
        "        X[f\"{f}:{c}\"] = X[f] * X[c]\n",
        "\n",
        "# Size × Bathroom\n",
        "X[\"Size:Bathroom\"] = house[\"Size\"] * house[\"Bathroom\"]\n",
        "\n",
        "# Add constant\n",
        "X = sm.add_constant(X)\n",
        "\n",
        "vif = pd.DataFrame({\n",
        "    \"feature\": X.columns,\n",
        "    \"VIF\": [variance_inflation_factor(X.values, i)\n",
        "            for i in range(X.shape[1])]\n",
        "})\n",
        "\n",
        "vif.sort_values(\"VIF\", ascending=False)"
      ],
      "metadata": {
        "id": "Hq3_GvaGdDR4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Main effects\n",
        "NUMERIC_FEATURES = [\n",
        "    \"Size\",\n",
        "    \"floor_ratio\",\n",
        "    \"Bathroom\"\n",
        "]\n",
        "\n",
        "CATEGORICAL_FEATURES = [\n",
        "    \"City\",\n",
        "    \"Furnishing_Status\",\n",
        "    \"Area_Type\"\n",
        "]\n",
        "\n",
        "# Interactions\n",
        "INTERACTIONS = [\n",
        "    \"Size:C(City)\",\n",
        "    \"C(Furnishing_Status):C(City)\",\n",
        "]\n",
        "\n",
        "# Main effects part\n",
        "main_effects = (\n",
        "    NUMERIC_FEATURES\n",
        "    + [f\"C({c})\" for c in CATEGORICAL_FEATURES]\n",
        ")\n",
        "\n",
        "# Full formula\n",
        "formula = \"log_Rent ~ \" + \" + \".join(main_effects + INTERACTIONS)\n",
        "\n",
        "model = smf.ols(formula, data=house).fit()\n",
        "print(model.summary())\n",
        "\n",
        "# Dummy encode categorical variables\n",
        "X = pd.get_dummies(\n",
        "    house[NUMERIC_FEATURES],\n",
        "    drop_first=True\n",
        ")\n",
        "\n",
        "# Add interaction terms manually\n",
        "# Size × City\n",
        "for col in X.filter(like=\"City_\").columns:\n",
        "    X[f\"Size:{col}\"] = house[\"Size\"] * X[col]\n",
        "\n",
        "# Furnishing × City\n",
        "for f in X.filter(like=\"Furnishing_Status_\").columns:\n",
        "    for c in X.filter(like=\"City_\").columns:\n",
        "        X[f\"{f}:{c}\"] = X[f] * X[c]\n",
        "\n",
        "\n",
        "# Add constant\n",
        "X = sm.add_constant(X)\n",
        "\n",
        "vif = pd.DataFrame({\n",
        "    \"feature\": X.columns,\n",
        "    \"VIF\": [variance_inflation_factor(X.values, i)\n",
        "            for i in range(X.shape[1])]\n",
        "})\n",
        "\n",
        "vif.sort_values(\"VIF\", ascending=False)"
      ],
      "metadata": {
        "id": "pG7lJ-jjrbsI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "VIFs indicate little multicollinearity present in the numeric part of the model.\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "9LDiWxdhr5Mh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# centering continuus variables to reduce multicollinearity\n",
        "house['Size_c'] = house['Size'] - house['Size'].mean()\n",
        "house['Bathroom_c'] = house['Bathroom'] - house['Bathroom'].mean()\n",
        "\n",
        "# Main effects\n",
        "NUMERIC_FEATURES = [\n",
        "    \"Size_c\",\n",
        "    \"floor_ratio\",\n",
        "    \"Bathroom_c\"\n",
        "]\n",
        "\n",
        "CATEGORICAL_FEATURES = [\n",
        "    \"City\",\n",
        "    \"Furnishing_Status\",\n",
        "    \"Area_Type\"\n",
        "]\n",
        "\n",
        "# Interactions\n",
        "INTERACTIONS = [\n",
        "\n",
        "]\n",
        "# Main effects part\n",
        "main_effects = (\n",
        "    NUMERIC_FEATURES\n",
        "    + [f\"C({c})\" for c in CATEGORICAL_FEATURES]\n",
        ")\n",
        "\n",
        "\n",
        "# Full formula\n",
        "formula = \"log_Rent ~ \" + \" + \".join(main_effects + INTERACTIONS)\n",
        "\n",
        "model = smf.ols(formula, data=house).fit()\n",
        "print(model.summary())\n",
        "\n",
        "model_initial_feature_engineering = model\n",
        "\n",
        "# Ensure numeric\n",
        "X_numeric = X.astype(float)\n",
        "vif = pd.DataFrame({\n",
        "    \"feature\": X_numeric.columns,\n",
        "    \"VIF\": [variance_inflation_factor(X_numeric.values, i) for i in range(X_numeric.shape[1])]\n",
        "})\n",
        "vif"
      ],
      "metadata": {
        "id": "hidPbD8fr1qG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This current model has nice R^2 but has trong multicollinearity problems. Residual analysis follows."
      ],
      "metadata": {
        "id": "Njx5q2XEuXOh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Baseline influence tables\n",
        "FEATURES = [\n",
        "    \"Size_c\",\n",
        "    \"floor_ratio\",\n",
        "    \"Bathroom_c\",\n",
        "    \"City\",\n",
        "    \"Furnishing_Status\",\n",
        "    \"Area_Type\",\n",
        "]\n",
        "\n",
        "def make_X(df, features=FEATURES):\n",
        "    \"\"\"Return design matrix with intercept.\"\"\"\n",
        "    return sm.add_constant(df[features], has_constant='add')\n",
        "\n",
        "# Get influence measures\n",
        "infl_base = model_initial_feature_engineering.get_influence()\n",
        "sf_base = infl_base.summary_frame()\n",
        "\n",
        "# Thresholds\n",
        "p_base = make_X(house).shape[1] - 1\n",
        "n_base = len(house)\n",
        "cook_thr_base = 4 / n_base\n",
        "lev_thr_base = 2 * (p_base + 1) / n_base\n",
        "\n",
        "# Count how many thresholds each point exceeds\n",
        "thresholds_exceeded = (\n",
        "    (sf_base['cooks_d'] > cook_thr_base).astype(int) +\n",
        "    (sf_base['hat_diag'] > lev_thr_base).astype(int) +\n",
        "    (sf_base['student_resid'].abs() > 3).astype(int) +\n",
        "    (sf_base['cooks_d'] > 0.5).astype(int)\n",
        ")\n",
        "\n",
        "# Flag points that exceed at least 2 thresholds\n",
        "flag_mask_base = thresholds_exceeded >= 2\n",
        "flagged_indices_base = house.index[flag_mask_base]\n",
        "\n",
        "print(f\"Number of points flagged: {flag_mask_base.sum()}\")\n",
        "\n",
        "print(f\"Baseline: {flag_mask_base.sum()} influential points flagged \"\n",
        "      f\"(Cook>{cook_thr_base:.4f} or leverage>{lev_thr_base:.4f} or |studentized|>3)\")\n",
        "\n",
        "# Rank top 20 by different influence metrics\n",
        "ranked = {\n",
        "    'DFFITS': sf_base['dffits'].abs().nlargest(20),\n",
        "    'Max|DFBETA|': pd.DataFrame(infl_base.dfbetas, columns=model_initial_feature_engineering.params.index).abs().max(axis=1).nlargest(20),\n",
        "    'Leverage': sf_base['hat_diag'].nlargest(20),\n",
        "    'CooksD': sf_base['cooks_d'].nlargest(20)\n",
        "}\n",
        "\n",
        "for key, series in ranked.items():\n",
        "    tbl = pd.DataFrame({\n",
        "        'row_index': series.index,  # using row indices instead of 'id'\n",
        "        key: series.values\n",
        "    })\n",
        "    print(f\"Baseline top 20 by {key}:\")\n",
        "    display(tbl)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "VCyHQsZUvAe3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Diagnostics helper\n",
        "def plot_diagnostics(model, sf_local, label, ax_row, cook_thr_val):\n",
        "    fitted = model.fittedvalues\n",
        "    resid = model.resid\n",
        "\n",
        "    # Residuals vs Fitted\n",
        "    ax_row[0].scatter(fitted, resid, alpha=0.5)\n",
        "    ax_row[0].axhline(0, color='red', linestyle='--')\n",
        "    ax_row[0].set_title(f'{label}: Residuals vs Fitted')\n",
        "    ax_row[0].set_xlabel('Fitted log-price')\n",
        "    ax_row[0].set_ylabel('Residuals')\n",
        "\n",
        "    # QQ plot\n",
        "    sm.qqplot(resid, ax=ax_row[1], line='s')\n",
        "    ax_row[1].set_title(f'{label}: QQ plot')\n",
        "\n",
        "    # Cook's distance\n",
        "    ax_row[2].stem(np.arange(len(sf_local)), sf_local['cooks_d'].values, basefmt=' ')\n",
        "    ax_row[2].axhline(cook_thr_val, color='orange', linestyle='--', label='Cook threshold')\n",
        "    ax_row[2].set_title(f\"{label}: Cook's distance\")\n",
        "    ax_row[2].legend()\n",
        "\n",
        "# Baseline diagnostics\n",
        "infl_base = model_initial_feature_engineering.get_influence()\n",
        "sf_base = infl_base.summary_frame()\n",
        "p_base = make_X(house).shape[1] - 1\n",
        "n_base = len(house)\n",
        "cook_thr_base = 4 / n_base\n",
        "\n",
        "# Flag influential points\n",
        "flag_mask_base = (\n",
        "    (sf_base['cooks_d'] > cook_thr_base) |\n",
        "    (sf_base['hat_diag'] > (2 * (p_base + 1) / n_base)) |\n",
        "    (sf_base['student_resid'].abs() > 3) |\n",
        "    (sf_base['cooks_d'] > 0.5)\n",
        ")\n",
        "flagged_indices_base = house.index[flag_mask_base]  # use row indices\n",
        "\n",
        "# Plot diagnostics: Residuals, QQ, Cook's distance\n",
        "fig, axes = plt.subplots(1, 3, figsize=(18, 5))  # 1 row, 3 columns\n",
        "plot_diagnostics(model_initial_feature_engineering, sf_base, 'Baseline', axes, cook_thr_base)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(f\"Baseline flagged rows: {len(flagged_indices_base)} (examples: {flagged_indices_base.tolist()[:10]})\")\n",
        "\n",
        "# Additional diagnostic: Scale-Location plot\n",
        "fig, ax = plt.subplots(figsize=(14, 5))  # single Axes object\n",
        "ax.scatter(model_initial_feature_engineering.fittedvalues,\n",
        "           np.sqrt(np.abs(sf_base['student_resid'])),\n",
        "           alpha=0.5)\n",
        "ax.set_xlabel('Fitted values')\n",
        "ax.set_ylabel('√|Standardized residuals|')\n",
        "ax.set_title('Baseline: Scale-Location Plot')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"\"\"\n",
        "Diagnostic Summary:\n",
        "- Residuals vs Fitted: Check for non-linearity and heteroscedasticity\n",
        "- QQ Plot: Check normality of residuals (deviations in tails indicate heavy-tailed errors)\n",
        "- Cook's Distance: Identifies influential observations\n",
        "- Scale-Location: Check for heteroscedasticity (spread should be constant)\n",
        "\n",
        "Observations:\n",
        "- Residuals vs Fitted: mostly linear and heteroscedastic, outliers can be seen\n",
        "- Q-Q Plot: Indicates extremal values, the middle is very nicely normal\n",
        "- Cooks distance: there are a few very distant observations\n",
        "- Scale-Location: Suggests good heteroscedaticity, shows outliers\n",
        "\"\"\")"
      ],
      "metadata": {
        "id": "TI17Ezc3ydtt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -------------------------------\n",
        "# Step 0: Reset index for filtered dataframe\n",
        "# -------------------------------\n",
        "thresholds_exceeded = (\n",
        "    (sf_base['cooks_d'] > cook_thr_base).astype(int) +\n",
        "    (sf_base['hat_diag'] > (2 * (p_base + 1) / n_base)).astype(int) +\n",
        "    (sf_base['student_resid'].abs() > 3).astype(int) +\n",
        "    (sf_base['cooks_d'] > 0.5).astype(int)\n",
        ")\n",
        "flag_mask_multi = thresholds_exceeded >= 2\n",
        "flagged_indices_multi = house.index[flag_mask_multi]\n",
        "\n",
        "houses_influentials_removed = house.drop(index=flagged_indices_multi).reset_index(drop=True)\n",
        "\n",
        "# -------------------------------\n",
        "# Step 1: Define features\n",
        "# -------------------------------\n",
        "numeric_features = ['Size_c', 'floor_ratio', 'Bathroom_c']\n",
        "categorical_features = ['City', 'Furnishing_Status', 'Area_Type']\n",
        "\n",
        "# -------------------------------\n",
        "# Step 2: One-hot encode categoricals after filtering\n",
        "# -------------------------------\n",
        "X_filtered = pd.get_dummies(\n",
        "    houses_influentials_removed[numeric_features + categorical_features],\n",
        "    drop_first=True\n",
        ")\n",
        "\n",
        "# Ensure all numeric\n",
        "X_filtered = X_filtered.astype(float)\n",
        "\n",
        "# Add constant for intercept\n",
        "X_filtered = sm.add_constant(X_filtered, has_constant='add')\n",
        "\n",
        "# -------------------------------\n",
        "# Step 3: Target variable\n",
        "# -------------------------------\n",
        "y_filtered = houses_influentials_removed['log_Rent'].astype(float)\n",
        "\n",
        "# -------------------------------\n",
        "# Step 4: Fit OLS\n",
        "# -------------------------------\n",
        "model_filtered = sm.OLS(y_filtered, X_filtered).fit()\n",
        "\n",
        "# -------------------------------\n",
        "# Step 5: Influence diagnostics\n",
        "# -------------------------------\n",
        "infl_filtered = model_filtered.get_influence()\n",
        "sf_filtered = infl_filtered.summary_frame()\n",
        "n_filtered = len(houses_influentials_removed)\n",
        "cook_thr_filtered = 4 / n_filtered\n",
        "\n",
        "# -------------------------------\n",
        "# Step 6: Plot diagnostics\n",
        "# -------------------------------\n",
        "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
        "plot_diagnostics(model_filtered, sf_filtered, 'Filtered', axes, cook_thr_filtered)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Scale-Location plot\n",
        "fig, ax = plt.subplots(figsize=(14, 5))\n",
        "ax.scatter(model_filtered.fittedvalues,\n",
        "           np.sqrt(np.abs(sf_filtered['student_resid'])),\n",
        "           alpha=0.5)\n",
        "ax.set_xlabel('Fitted values')\n",
        "ax.set_ylabel('√|Standardized residuals|')\n",
        "ax.set_title('Filtered: Scale-Location Plot')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(f\"\"\"\n",
        "Filtered Diagnostic Summary:\n",
        "- Number of observations removed: {flag_mask_multi.sum()}\n",
        "- Shape of filtered dataset: {houses_influentials_removed.shape}\n",
        "- Number of features used in model: {X_filtered.shape[1]}\n",
        "\"\"\")"
      ],
      "metadata": {
        "id": "hnKZjK-I2MU5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(model_filtered.summary())"
      ],
      "metadata": {
        "id": "5GUDX3o0aDr7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# X_filtered should already have constant and all numeric columns\n",
        "vif_df = pd.DataFrame({\n",
        "    \"feature\": X_filtered.columns,\n",
        "    \"VIF\": [variance_inflation_factor(X_filtered.values, i) for i in range(X_filtered.shape[1])]\n",
        "})\n",
        "\n",
        "# Sort by VIF descending\n",
        "vif_df = vif_df.sort_values(\"VIF\", ascending=False).reset_index(drop=True)\n",
        "print(vif_df)"
      ],
      "metadata": {
        "id": "9iOy-lfz475W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "myKwxTgJwXIO"
      },
      "source": [
        "\n",
        "## Questions for a linear regression analysis of house rent\n",
        "\n",
        "When building a linear regression model for rent, it is useful to think\n",
        "in terms of a workflow:\n",
        "\n",
        "1. **Understand the data**\n",
        "   - What is the response variable (e.g. `Rent`)?  \n",
        "     What are the main predictor types (numeric, categorical, locations,\n",
        "     amenities)?\n",
        "   - Are there obvious data quality issues (missing values, impossible\n",
        "     values, outliers)?\n",
        "\n",
        "2. **Preprocessing and feature engineering**\n",
        "   - How should categorical variables (e.g. city, furnishing status,\n",
        "     point of contact) be encoded for a linear model (one?hot encoding,\n",
        "     target encoding, etc.)?\n",
        "   - Which numeric variables might benefit from scaling (standardization\n",
        "     or robust scaling), and why can this matter for regularized\n",
        "     regression?\n",
        "   - Are there interactions that are conceptually meaningful\n",
        "     (e.g. `BHK , Size`, `City , DistanceFromMainArea`)?\n",
        "   - Can we create more interpretable features (e.g. rent per square\n",
        "     foot, distance to city centre bins)?\n",
        "\n",
        "3. **Transformations of response and regressors**\n",
        "   - Is the distribution of `Rent` highly skewed or heavy tailed? Would a\n",
        "     log transformation (modeling $\\log(\\text{Rent})$) stabilize\n",
        "     variance and make residuals closer to normal?\n",
        "   - Do some predictors show non linear relationships with rent? Would\n",
        "     polynomial terms, splines, or monotone transforms (log, square\n",
        "     root) be appropriate?\n",
        "   - Are there predictors that should be centered or standardized before\n",
        "     creating interaction or polynomial terms?\n",
        "\n",
        "4. **Model specification and selection**\n",
        "   - Start with a simple baseline: which variables should be included in\n",
        "     a first OLS model, and how do residual plots look?\n",
        "   - How to compare alternative specifications\n",
        "     (different sets of features, transformed vs untransformed variables)\n",
        "     using cross validation or a validation set?\n",
        "   - When is it useful to move from plain OLS to regularized models such\n",
        "     as ridge or lasso (e.g. many correlated predictors, high variance)?\n",
        "\n",
        "5. **Model evaluation and diagnostics**\n",
        "   - How to check linear model assumptions: residual vs fitted plots,\n",
        "     QQ plots, heteroscedasticity, influential observations?\n",
        "   - Which error metrics are most relevant here\n",
        "     (RMSE, MAE, MAPE)?  How do training and test errors compare\n",
        "     (overfitting vs underfitting)?\n",
        "   - Are there systematic groups of houses (by city, BHK, furnishing)\n",
        "     for which the model performs much worse, suggesting missing\n",
        "     structure or interactions?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "goxjHeXZwXIP"
      },
      "source": [
        "\n",
        "### More detailed questions to explore\n",
        "\n",
        "- **Preprocessing**\n",
        "  - How should missing values be handled for each variable (impute,\n",
        "    drop, or create explicit missing indicators)?\n",
        "  - Do we need to cap or Winsorize extreme values of `Rent` or `Size`\n",
        "    before fitting a linear model?\n",
        "  - Are there rare categories (e.g. cities or furnishing statuses with\n",
        "    very few observations) that should be grouped together?\n",
        "\n",
        "- **Transformations and linearity**\n",
        "  - Plot `Rent` (or $\\log(\\text{Rent})$) against key predictors:\n",
        "    `Size`, `BHK`, `Bathroom`, `City`, etc.  Do the relationships look\n",
        "    approximately linear after transformation?\n",
        "  - Would modeling $\\log(\\text{Rent})$ make residuals more symmetric and\n",
        "    reduce heteroscedasticity?\n",
        "\n",
        "- **Multicollinearity and regularization**\n",
        "  - Are some predictors strongly correlated (e.g. `Size` and `BHK`)?  How\n",
        "    do VIFs and condition numbers look for the chosen design matrix?\n",
        "  - How do ridge and lasso behave in this dataset in terms of coefficient\n",
        "    shrinkage and variable selection?\n",
        "  - Which predictors consistently get selected by lasso across\n",
        "    cross?validation folds?\n",
        "\n",
        "- **Model selection and validation**\n",
        "  - How does test error change when we:\n",
        "    1. Add more predictors,\n",
        "    2. Add interaction terms,\n",
        "    3. Add polynomial terms,\n",
        "    4. Switch from OLS to ridge/lasso?\n",
        "  - How to choose the final model: by minimum cross?validated RMSE,\n",
        "    parsimony (fewest predictors), or domain interpretability?\n",
        "\n",
        "Use these questions as a checklist to design your own modeling pipeline\n",
        "for the house rent dataset using linear regression and its regularized\n",
        "variants.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "There are no NaNs. There seem to be no immediate outliers."
      ],
      "metadata": {
        "id": "kL2J6rc08et3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ARyiIgPpV7cC"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ztaVvcBEWNH8"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tzp64AaEWNK-"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}